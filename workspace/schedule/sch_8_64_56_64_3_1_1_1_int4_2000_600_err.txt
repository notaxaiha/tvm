@relu_8_64_56_64_3_1_4_1 = primfn(A_1: handle, W_1: handle, output_unpack_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "relu_8_64_56_64_3_1_4_1", "tir.noalias": True}
  buffers = {output_unpack: Buffer(output_unpack_2: Pointer(int32), int32, [56, 56, 8, 64], []),
             A: Buffer(A_2: Pointer(int4), int4, [56, 56, 8, 64], []),
             W: Buffer(W_2: Pointer(int4), int4, [3, 3, 64, 64], [])}
  buffer_map = {A_1: A, W_1: W, output_unpack_1: output_unpack} {
  allocate(packed_kernel: Pointer(global int4), int4, [36864]), storage_scope = global {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 36;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    packed_kernel[((blockIdx.x*1024) + threadIdx.x)] = (int4*)W_2[(((((blockIdx.x*1024) + (floordiv(threadIdx.x, 512)*512)) + (floordiv(floormod(threadIdx.x, 256), 32)*64)) + (floordiv(floormod(threadIdx.x, 512), 256)*32)) + floormod(threadIdx.x, 32))]
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 392;
    allocate(Conv: Pointer(shared int32), int32, [((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*512)]), storage_scope = shared;
    allocate(Conv.wmma.accumulator: Pointer(wmma.accumulator int32), int32, [((((floordiv(((h.w.fused.n.fused.outer.outer: int32*8) + 7), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))) + 1) - floordiv((h.w.fused.n.fused.outer.outer*8), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*512)]), storage_scope = wmma.accumulator;
    allocate(pad_data.shared: Pointer(shared int4), int4, [1536]), storage_scope = shared;
    allocate(pad_data.shared.wmma.matrix_a: Pointer(wmma.matrix_a int4), int4, [512]), storage_scope = wmma.matrix_a;
    allocate(packed_kernel.shared: Pointer(shared int4), int4, [4096]), storage_scope = shared;
    allocate(packed_kernel.shared.wmma.matrix_b: Pointer(wmma.matrix_b int4), int4, [4096]), storage_scope = wmma.matrix_b;
    allocate(pad_data.shared.wmma.matrix_a_1: Pointer(wmma.matrix_a int4), int4, [512]), storage_scope = wmma.matrix_a;
    allocate(packed_kernel.shared.wmma.matrix_b_1: Pointer(wmma.matrix_b int4), int4, [4096]), storage_scope = wmma.matrix_b;
    allocate(Conv.wmma.accumulator_1: Pointer(wmma.accumulator int32), int32, [((((floordiv((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1: int32*8)) + 7), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))) + 1) - floordiv(((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*512)]), storage_scope = wmma.accumulator;
    allocate(pad_data.shared.wmma.matrix_a_2: Pointer(wmma.matrix_a int4), int4, [512]), storage_scope = wmma.matrix_a;
    allocate(packed_kernel.shared.wmma.matrix_b_2: Pointer(wmma.matrix_b int4), int4, [4096]), storage_scope = wmma.matrix_b;
    allocate(pad_data.shared.wmma.matrix_a_3: Pointer(wmma.matrix_a int4), int4, [512]), storage_scope = wmma.matrix_a;
    allocate(packed_kernel.shared.wmma.matrix_b_3: Pointer(wmma.matrix_b int4), int4, [4096]), storage_scope = wmma.matrix_b;
    attr [IterVar(blockIdx.y: int32, (nullptr), "ThreadIndex", "blockIdx.y")] "thread_extent" = 1 {
      for (h.w.fused.n.fused.outer.outer, 0, floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)) {
        attr [IterVar(threadIdx.y: int32, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.z: int32, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1 {
          for (h.c: int32, 0, ((floordiv(((h.w.fused.n.fused.outer.outer*8) + 7), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))) + 1) - floordiv((h.w.fused.n.fused.outer.outer*8), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))))) {
            for (w.c: int32, 0, (min(56, (floormod(((blockIdx.x_1*8) + 7), 56) + 1)) - (floormod(blockIdx.x_1, 7)*8))) {
              for (o.c.init: int32, 0, 8) "unroll" {
                @tir.tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((((h.c*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*8) + (w.c*8)) + o.c.init), 0f32, dtype=handle)
              }
              for (kh: int32, 0, 3) "unroll" {
                attr [pad_data.shared] "double_buffer_scope" = 1;
                for (ax1: int32, 0, 3) "unroll" {
                  for (ax3: int32, 0, 2) "unroll" {
                    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 32;
                    if (0 <= (((floordiv(blockIdx.x_1, 7) + h.c) + floordiv((h.w.fused.n.fused.outer.outer*8), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) + kh)) {
                      if ((((floordiv(blockIdx.x_1, 7) + h.c) + floordiv((h.w.fused.n.fused.outer.outer*8), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) + kh) < 58) {
                        pad_data.shared[ramp((((ax1*512) + (ax3*256)) + (threadIdx.x_1*8)), 1, 8)] = @tir.if_then_else(((((1 <= (((floordiv(blockIdx.x_1, 7) + h.c) + floordiv((h.w.fused.n.fused.outer.outer*8), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) + kh)) && ((((floordiv(blockIdx.x_1, 7) + h.c) + floordiv((h.w.fused.n.fused.outer.outer*8), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) + kh) < 57)) && (1 <= (((floormod(blockIdx.x_1, 7)*8) + ax1) + w.c))) && ((((floormod(blockIdx.x_1, 7)*8) + ax1) + w.c) < 57)), (int4x8*)A_2[ramp(((((((((((h.c*28672) + (floordiv((h.w.fused.n.fused.outer.outer*8), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*28672)) + (kh*28672)) + (blockIdx.x_1*4096)) + (ax1*512)) + (w.c*512)) + (floordiv(threadIdx.x_1, 4)*64)) + (ax3*32)) + (floormod(threadIdx.x_1, 4)*8)) - 29184), 1, 8)], broadcast(0i4, 8), dtype=int4x8)
                      }
                    }
                  }
                }
                for (kw: int32, 0, 3) "unroll" {
                  for (ax3_1: int32, 0, 2) "unroll" {
                    if (0 <= (((floordiv(blockIdx.x_1, 7) + h.c) + floordiv((h.w.fused.n.fused.outer.outer*8), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) + kh)) {
                      if ((((floordiv(blockIdx.x_1, 7) + h.c) + floordiv((h.w.fused.n.fused.outer.outer*8), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) + kh) < 58) {
                        @tir.tvm_load_matrix_sync(pad_data.shared.wmma.matrix_a, 8, 8, 32, ax3_1, @tir.tvm_access_ptr(@tir.type_annotation(, dtype=int4), pad_data.shared, ((kw*512) + (ax3_1*256)), 256, 1, dtype=handle), 32, "row_major", dtype=handle)
                      }
                    }
                  }
                  for (ax2: int32, 0, 8) "unroll" {
                    for (ax3.inner.inner: int32, 0, 2) "unroll" {
                      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 32;
                      packed_kernel.shared[ramp((((ax2*512) + (ax3.inner.inner*256)) + (threadIdx.x_1*8)), 1, 8)] = (int4x8*)packed_kernel[ramp((((((kh*12288) + (kw*4096)) + (ax2*512)) + (ax3.inner.inner*256)) + (threadIdx.x_1*8)), 1, 8)]
                    }
                  }
                  for (ax2_1: int32, 0, 8) "unroll" {
                    for (ax3_2: int32, 0, 2) "unroll" {
                      @tir.tvm_load_matrix_sync(packed_kernel.shared.wmma.matrix_b, 8, 8, 32, ((ax2_1*2) + ax3_2), @tir.tvm_access_ptr(@tir.type_annotation(, dtype=int4), packed_kernel.shared, ((ax2_1*512) + (ax3_2*256)), 256, 1, dtype=handle), 32, "col_major", dtype=handle)
                    }
                  }
                  for (ic.inner: int32, 0, 2) "unroll" {
                    for (o.c: int32, 0, 8) "unroll" {
                      if (0 <= ((floordiv(blockIdx.x_1, 7) + h.c) + floordiv((h.w.fused.n.fused.outer.outer*8), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))))) {
                        if (((floordiv(blockIdx.x_1, 7) + h.c) + floordiv((h.w.fused.n.fused.outer.outer*8), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) < 56) {
                          @tir.tvm_mma_sync(Conv.wmma.accumulator, ((((h.c*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*8) + (w.c*8)) + o.c), pad_data.shared.wmma.matrix_a, ic.inner, packed_kernel.shared.wmma.matrix_b, ((o.c*2) + ic.inner), Conv.wmma.accumulator, ((((h.c*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*8) + (w.c*8)) + o.c), dtype=handle)
                        }
                      }
                    }
                  }
                }
              }
            }
          }
          for (h.w.fused.n.fused.inner: int32, 0, 8) "unroll" {
            for (o.inner: int32, 0, 8) "unroll" {
              if (floordiv(((h.w.fused.n.fused.outer.outer*8) + h.w.fused.n.fused.inner), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))) < ((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))) {
                if (floormod(((h.w.fused.n.fused.outer.outer*8) + h.w.fused.n.fused.inner), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))) < ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))) {
                  if (0 <= (floordiv(blockIdx.x_1, 7) + floordiv(((h.w.fused.n.fused.outer.outer*8) + h.w.fused.n.fused.inner), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))))) {
                    if ((floordiv(blockIdx.x_1, 7) + floordiv(((h.w.fused.n.fused.outer.outer*8) + h.w.fused.n.fused.inner), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) < 56) {
                      if (0 <= ((floormod(blockIdx.x_1, 7)*8) + floormod(((h.w.fused.n.fused.outer.outer*8) + h.w.fused.n.fused.inner), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))))) {
                        if (((floormod(blockIdx.x_1, 7)*8) + floormod(((h.w.fused.n.fused.outer.outer*8) + h.w.fused.n.fused.inner), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) < 56) {
                          @tir.tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, (((((floordiv(((h.w.fused.n.fused.outer.outer*8) + h.w.fused.n.fused.inner), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))) - floordiv((h.w.fused.n.fused.outer.outer*8), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*8) + (floormod(((h.w.fused.n.fused.outer.outer*8) + h.w.fused.n.fused.inner), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*8)) + o.inner), @tir.tvm_access_ptr(@tir.type_annotation(, dtype=int32), Conv, (((h.w.fused.n.fused.outer.outer*4096) + (h.w.fused.n.fused.inner*512)) + (o.inner*64)), 64, 2, dtype=handle), 8, "row_major", dtype=handle)
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
      for (h.w.fused.n.fused.outer.outer_1, 0, floordiv((floormod((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8) + 7), 8)) {
        attr [IterVar(threadIdx.y, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
        attr [IterVar(threadIdx.z, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1 {
          for (h.c_1: int32, 0, ((floordiv((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)) + 7), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))) + 1) - floordiv(((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))))) {
            for (w.c_1: int32, 0, (min(56, (floormod(((blockIdx.x_1*8) + 7), 56) + 1)) - (floormod(blockIdx.x_1, 7)*8))) {
              for (o.c.init_1: int32, 0, 8) "unroll" {
                @tir.tvm_fill_fragment(Conv.wmma.accumulator_1, 8, 8, 32, ((((h.c_1*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*8) + (w.c_1*8)) + o.c.init_1), 0f32, dtype=handle)
              }
              for (kh_1: int32, 0, 3) "unroll" {
                attr [pad_data.shared_1: Pointer(shared int4)] "double_buffer_scope" = 1;
                for (ax1_1: int32, 0, 3) "unroll" {
                  for (ax3_3: int32, 0, 2) "unroll" {
                    attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 32;
                    if (0 <= (((floordiv(blockIdx.x_1, 7) + h.c_1) + floordiv(((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) + kh_1)) {
                      if ((((floordiv(blockIdx.x_1, 7) + h.c_1) + floordiv(((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) + kh_1) < 58) {
                        pad_data.shared[ramp((((ax1_1*512) + (ax3_3*256)) + (threadIdx.x_1*8)), 1, 8)] = @tir.if_then_else(((((1 <= (((floordiv(blockIdx.x_1, 7) + h.c_1) + floordiv(((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) + kh_1)) && ((((floordiv(blockIdx.x_1, 7) + h.c_1) + floordiv(((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) + kh_1) < 57)) && (1 <= (((floormod(blockIdx.x_1, 7)*8) + ax1_1) + w.c_1))) && ((((floormod(blockIdx.x_1, 7)*8) + ax1_1) + w.c_1) < 57)), (int4x8*)A_2[ramp(((((((((((h.c_1*28672) + (floordiv(((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*28672)) + (kh_1*28672)) + (blockIdx.x_1*4096)) + (ax1_1*512)) + (w.c_1*512)) + (floordiv(threadIdx.x_1, 4)*64)) + (ax3_3*32)) + (floormod(threadIdx.x_1, 4)*8)) - 29184), 1, 8)], broadcast(0i4, 8), dtype=int4x8)
                      }
                    }
                  }
                }
                for (kw_1: int32, 0, 3) "unroll" {
                  for (ax3_4: int32, 0, 2) "unroll" {
                    if (0 <= (((floordiv(blockIdx.x_1, 7) + h.c_1) + floordiv(((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) + kh_1)) {
                      if ((((floordiv(blockIdx.x_1, 7) + h.c_1) + floordiv(((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) + kh_1) < 58) {
                        @tir.tvm_load_matrix_sync(pad_data.shared.wmma.matrix_a_2, 8, 8, 32, ax3_4, @tir.tvm_access_ptr(@tir.type_annotation(, dtype=int4), pad_data.shared, ((kw_1*512) + (ax3_4*256)), 256, 1, dtype=handle), 32, "row_major", dtype=handle)
                      }
                    }
                  }
                  for (ax2_2: int32, 0, 8) "unroll" {
                    for (ax3.inner.inner_1: int32, 0, 2) "unroll" {
                      attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 32;
                      packed_kernel.shared[ramp((((ax2_2*512) + (ax3.inner.inner_1*256)) + (threadIdx.x_1*8)), 1, 8)] = (int4x8*)packed_kernel[ramp((((((kh_1*12288) + (kw_1*4096)) + (ax2_2*512)) + (ax3.inner.inner_1*256)) + (threadIdx.x_1*8)), 1, 8)]
                    }
                  }
                  for (ax2_3: int32, 0, 8) "unroll" {
                    for (ax3_5: int32, 0, 2) "unroll" {
                      @tir.tvm_load_matrix_sync(packed_kernel.shared.wmma.matrix_b_2, 8, 8, 32, ((ax2_3*2) + ax3_5), @tir.tvm_access_ptr(@tir.type_annotation(, dtype=int4), packed_kernel.shared, ((ax2_3*512) + (ax3_5*256)), 256, 1, dtype=handle), 32, "col_major", dtype=handle)
                    }
                  }
                  for (ic.inner_1: int32, 0, 2) "unroll" {
                    for (o.c_1: int32, 0, 8) "unroll" {
                      if (0 <= ((floordiv(blockIdx.x_1, 7) + h.c_1) + floordiv(((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))))) {
                        if (((floordiv(blockIdx.x_1, 7) + h.c_1) + floordiv(((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) < 56) {
                          @tir.tvm_mma_sync(Conv.wmma.accumulator_1, ((((h.c_1*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*8) + (w.c_1*8)) + o.c_1), pad_data.shared.wmma.matrix_a_2, ic.inner_1, packed_kernel.shared.wmma.matrix_b_2, ((o.c_1*2) + ic.inner_1), Conv.wmma.accumulator_1, ((((h.c_1*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*8) + (w.c_1*8)) + o.c_1), dtype=handle)
                        }
                      }
                    }
                  }
                }
              }
            }
          }
          for (h.w.fused.n.fused.inner_1: int32, 0, 8) "unroll" {
            for (o.inner_1: int32, 0, 8) "unroll" {
              if (floordiv((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)) + h.w.fused.n.fused.inner_1), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))) < ((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))) {
                if (floormod((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)) + h.w.fused.n.fused.inner_1), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))) < ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))) {
                  if ((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)) + h.w.fused.n.fused.inner_1) < (((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) {
                    if ((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)) + h.w.fused.n.fused.inner_1) < (((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) {
                      if (0 <= (floordiv(blockIdx.x_1, 7) + floordiv((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)) + h.w.fused.n.fused.inner_1), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))))) {
                        if ((floordiv(blockIdx.x_1, 7) + floordiv((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)) + h.w.fused.n.fused.inner_1), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) < 56) {
                          if (0 <= ((floormod(blockIdx.x_1, 7)*8) + floormod((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)) + h.w.fused.n.fused.inner_1), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))))) {
                            if (((floormod(blockIdx.x_1, 7)*8) + floormod((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)) + h.w.fused.n.fused.inner_1), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))) < 56) {
                              @tir.tvm_store_matrix_sync(Conv.wmma.accumulator_1, 8, 8, 32, (((((floordiv((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)) + h.w.fused.n.fused.inner_1), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))) - floordiv(((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*8) + (floormod((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*8) + (h.w.fused.n.fused.outer.outer_1*8)) + h.w.fused.n.fused.inner_1), ((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*8)) + o.inner_1), @tir.tvm_access_ptr(@tir.type_annotation(, dtype=int32), Conv, ((((floordiv((((floordiv(((blockIdx.x_1*8) + 7), 56) + 1) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8))), 8)*4096) + (h.w.fused.n.fused.outer.outer_1*4096)) + (h.w.fused.n.fused.inner_1*512)) + (o.inner_1*64)), 64, 2, dtype=handle), 8, "row_major", dtype=handle)
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
      attr [IterVar(threadIdx.y, (nullptr), "ThreadIndex", "threadIdx.y")] "thread_extent" = 1;
      attr [IterVar(threadIdx.z, (nullptr), "ThreadIndex", "threadIdx.z")] "thread_extent" = 1;
      for (h.inner.w.fused.n.outer.fused.inner: int32, 0, 8) "unroll" {
        for (o.outer.inner: int32, 0, 8) "unroll" {
          for (n.inner.o.inner.fused.outer: int32, 0, 2) "unroll" {
            attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 32;
            output_unpack_2[((((((blockIdx.x_1*4096) + (h.inner.w.fused.n.outer.fused.inner*512)) + (n.inner.o.inner.fused.outer*256)) + (floordiv(threadIdx.x_1, 8)*64)) + (o.outer.inner*8)) + floormod(threadIdx.x_1, 8))] = (int32*)Conv[((((((((floordiv(((blockIdx.x_1*8) + h.inner.w.fused.n.outer.fused.inner), 56) - floordiv(blockIdx.x_1, 7))*((floormod(((blockIdx.x_1*8) + 7), 56) + 1) - (floormod(blockIdx.x_1, 7)*8)))*512) + (floormod(((blockIdx.x_1*8) + h.inner.w.fused.n.outer.fused.inner), 56)*512)) + (o.outer.inner*64)) + (n.inner.o.inner.fused.outer*32)) + threadIdx.x_1) - (floormod(blockIdx.x_1, 7)*4096))]
          }
        }
      }
    }
  }
